# ğŸ“ Pasta LLM - Large Language Models

Esta pasta contÃ©m todos os mÃ³dulos relacionados a modelos de linguagem (Large Language Models) e integraÃ§Ã£o com IA generativa.

## ğŸ—‚ï¸ **Estrutura da Pasta:**

```
.kamila/llm/
â”œâ”€â”€ README.md                    # Este arquivo
â”œâ”€â”€ gemini_engine.py            # Motor Google Gemini AI
â”œâ”€â”€ ai_studio_integration.py    # IntegraÃ§Ã£o com AI Studio
â”œâ”€â”€ test_llm_modules.py         # Testes dos mÃ³dulos LLM
â”œâ”€â”€ requirements_gemini.txt      # DependÃªncias do Gemini
â””â”€â”€ main_with_llm.py           # Main com integraÃ§Ã£o LLM
```

## ğŸ¤– **MÃ³dulos DisponÃ­veis:**

### **1. Gemini Engine (`gemini_engine.py`)**
- **FunÃ§Ã£o:** IntegraÃ§Ã£o com Google Gemini Pro
- **Recursos:**
  - GeraÃ§Ã£o de texto avanÃ§ada
  - Chat completion
  - HistÃ³rico de conversaÃ§Ã£o
  - Modo simulado (sem API)
  - AnÃ¡lise de contexto

### **2. AI Studio Integration (`ai_studio_integration.py`)**
- **FunÃ§Ã£o:** IntegraÃ§Ã£o com Google AI Studio
- **Recursos:**
  - MÃºltiplos modelos generativos
  - AnÃ¡lise de sentimento
  - GeraÃ§Ã£o de texto personalizada
  - Suporte a diferentes temperaturas
  - Modo simulado

## ğŸš€ **Como Usar:**

### **InstalaÃ§Ã£o:**
```bash
# Instalar dependÃªncias
pip install -r .kamila/llm/requirements_gemini.txt
```

### **ExecuÃ§Ã£o BÃ¡sica:**
```bash
# Executar assistente com LLM
python .kamila/llm/main_with_llm.py

# Testar mÃ³dulos LLM
python .kamila/llm/test_llm_modules.py
```

### **ImportaÃ§Ã£o nos Outros MÃ³dulos:**
```python
# Importar mÃ³dulos LLM
from llm.gemini_engine import GeminiEngine
from llm.ai_studio_integration import AIStudioIntegration

# Inicializar engines
gemini = GeminiEngine()
ai_studio = AIStudioIntegration()

# Usar funcionalidades
response = gemini.chat("OlÃ¡! Como vocÃª estÃ¡?")
sentiment = ai_studio.analyze_sentiment("Estou feliz!")
```

## âš™ï¸ **ConfiguraÃ§Ã£o:**

### **VariÃ¡veis de Ambiente (.kamila/.env):**
```env
# API Keys para LLM
GOOGLE_AI_API_KEY=sua_chave_google_ai_aqui

# ConfiguraÃ§Ãµes LLM
LLM_MODEL=gemini-pro
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2048
```

### **Modo Simulado:**
Se nÃ£o houver API key configurada, os mÃ³dulos funcionarÃ£o em modo simulado com respostas prÃ©-programadas.

## ğŸ§ª **Testes:**

### **Executar Todos os Testes:**
```bash
python .kamila/llm/test_llm_modules.py
```

### **Testes Individuais:**
```python
from llm.gemini_engine import GeminiEngine
from llm.ai_studio_integration import AIStudioIntegration

# Testar Gemini
gemini = GeminiEngine()
print(gemini.chat("OlÃ¡!"))

# Testar AI Studio
ai_studio = AIStudioIntegration()
print(ai_studio.generate_text("Conte uma piada"))
```

## ğŸ“Š **Funcionalidades AvanÃ§adas:**

### **AnÃ¡lise de Sentimento:**
```python
from llm.ai_studio_integration import AIStudioIntegration

ai_studio = AIStudioIntegration()
result = ai_studio.analyze_sentiment("Estou muito feliz hoje!")
print(result)
# Output: {'sentimento': 'positivo', 'confianca': 0.8, 'emocoes': ['feliz', 'contente']}
```

### **Chat com Contexto:**
```python
from llm.gemini_engine import GeminiEngine

gemini = GeminiEngine()
context = {
    'user_name': 'JoÃ£o',
    'mood': 'alegre',
    'conversation_history': [...]
}
response = gemini.chat("Como vocÃª estÃ¡?", context)
```

## ğŸ”§ **Troubleshooting:**

### **Problema: ImportError**
```bash
# SoluÃ§Ã£o: Verificar se estÃ¡ na pasta correta
cd /caminho/para/projeto/kamila
python .kamila/llm/test_llm_modules.py
```

### **Problema: API Key nÃ£o configurada**
- Os mÃ³dulos funcionarÃ£o em modo simulado
- Configure `GOOGLE_AI_API_KEY` no arquivo `.kamila/.env`
- Obtenha chave em: https://aistudio.google.com/

### **Problema: MÃ³dulos nÃ£o encontrados**
```bash
# SoluÃ§Ã£o: Instalar dependÃªncias
pip install -r .kamila/llm/requirements_gemini.txt
```

## ğŸ“ˆ **Performance:**

- **Modo Simulado:** Respostas instantÃ¢neas
- **Modo API:** LatÃªncia de 1-3 segundos
- **MemÃ³ria:** ~50MB por instÃ¢ncia
- **CPU:** Uso mÃ­nimo em modo simulado

## ğŸ”„ **AtualizaÃ§Ãµes:**

Para atualizar os mÃ³dulos LLM:
```bash
pip install --upgrade google-generativeai
```

## ğŸ“ **Logs:**

Os mÃ³dulos geram logs detalhados em:
- `logs/kamila.log` (logs principais)
- Console (logs em tempo real)

## ğŸ¯ **PrÃ³ximos Passos:**

1. **IntegraÃ§Ã£o com outros LLMs:**
   - OpenAI GPT
   - Anthropic Claude
   - Modelos locais (Llama, etc.)

2. **Funcionalidades AvanÃ§adas:**
   - GeraÃ§Ã£o de imagens
   - AnÃ¡lise de Ã¡udio
   - TraduÃ§Ã£o em tempo real

3. **OtimizaÃ§Ã£o:**
   - Cache de respostas
   - CompressÃ£o de contexto
   - Processamento em lote

---

**ğŸ“ Suporte:** Para problemas ou dÃºvidas, consulte os logs ou abra uma issue no repositÃ³rio.

**ğŸ¤ ContribuiÃ§Ã£o:** Novos mÃ³dulos LLM sÃ£o bem-vindos! Siga o padrÃ£o dos mÃ³dulos existentes.
